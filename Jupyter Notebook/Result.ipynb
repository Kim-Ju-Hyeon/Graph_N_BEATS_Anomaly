{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9051dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db654cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from utils.result_visualization import *\n",
    "from utils.scalers import *\n",
    "from dataset.sea_fog_dataset import Temporal_Graph_Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f09f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20c4f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hour == 1:\n",
    "    input_length = 120\n",
    "    output_length = 6\n",
    "    \n",
    "elif hour == 3:\n",
    "    input_length = 120\n",
    "    output_length = 18\n",
    "    \n",
    "elif hour == 6:\n",
    "    input_length = 102\n",
    "    output_length = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7acbed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../exp/1212/IC_PN_BEATS/forecast_6hour_regression_all_combine_loss/1212_183337',\n",
       " '../exp/1212/IC_PN_BEATS/forecast_6hour_regression_all_single_loss/1212_200752',\n",
       " '../exp/1212/IC_PN_BEATS/forecast_6hour_regression_vis_combine_loss/1212_214019',\n",
       " '../exp/1212/IC_PN_BEATS/forecast_6hour_regression_vis_single_loss/1212_231549']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = glob(f'../exp/1212/IC_PN_BEATS/forecast_{hour}hour*/*')\n",
    "dirs.sort()\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4281c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_num = [10, 21, 32, 43, 54]\n",
    "loss_list = ['Loss_1,2', 'Loss_2', 'Loss_1,3', 'Loss_3']\n",
    "port_list = ['증산도', '불무기도', '장도', '목포', '여수항']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25c1f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('../src/data/SeaFog/graph_signal/scaler.pickle', 'rb'))\n",
    "mean, std = scaler.x_shift, scaler.x_scale\n",
    "\n",
    "mean = np.array(mean)\n",
    "std = np.array(std)\n",
    "\n",
    "mean = mean[target_col_num]\n",
    "std = std[target_col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfd96727",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Temporal_Graph_Signal('std')\n",
    "loader.path = '../src/data/SeaFog/graph_signal'\n",
    "loader.preprocess_dataset()\n",
    "\n",
    "train_dataset, _, test_dataset = loader.get_dataset(\n",
    "            num_timesteps_in=input_length,\n",
    "            num_timesteps_out=output_length,\n",
    "            batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d8a85",
   "metadata": {},
   "source": [
    "train_anomaly = []\n",
    "for batch in train_dataset[0]:\n",
    "    train_anomaly.append(batch.anomaly)\n",
    "train_anomaly = torch.stack(train_anomaly, axis=0)\n",
    "\n",
    "train_fog = sum(train_anomaly)\n",
    "\n",
    "print(train_fog)\n",
    "print(train_fog / train_anomaly.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b8b3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_anomaly = []\n",
    "for batch in test_dataset:\n",
    "    target_anomaly.append(batch.anomaly)\n",
    "target_anomaly = torch.stack(target_anomaly, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19d967e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result = {loss: {} for loss in loss_list}\n",
    "\n",
    "for exp_dir in dirs:\n",
    "    if exp_dir.split('/')[-2].split('_')[-3] == 'all':\n",
    "        if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "            name = 'Loss_1,2'\n",
    "        else:\n",
    "            name = \"Loss_2\"\n",
    "    else:\n",
    "        if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "            name = 'Loss_1,3'\n",
    "        else:\n",
    "            name = \"Loss_3\"\n",
    "            \n",
    "    config, _, test_result = get_exp_result_files(exp_dir)\n",
    "    \n",
    "    if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "        pred_anomaly = torch.sigmoid(torch.Tensor(test_result['anomaly_pred'])) > 0.5\n",
    "        \n",
    "    else:\n",
    "        node_by_node_pred = []\n",
    "        forecast = test_result['forecast'].squeeze()\n",
    "        for node in range(5):\n",
    "            port_forecast = forecast[:,node,:]\n",
    "\n",
    "            inv_port_forecast = inv_std_scaler(port_forecast.reshape(-1), mean[node], std[node])\n",
    "            inv_port_forecast = inv_port_forecast.reshape(forecast.shape[0], -1)\n",
    "\n",
    "            inv_port_forecast = inv_port_forecast[:, -1]\n",
    "\n",
    "            pred_anomaly = inv_port_forecast < 1000\n",
    "\n",
    "            node_by_node_pred.append(torch.Tensor(pred_anomaly))\n",
    "\n",
    "        pred_anomaly = torch.stack(node_by_node_pred, axis=0).T\n",
    "        \n",
    "    \n",
    "    result = {'Acc': 0, 'Precision': 0, 'Recall': 0, 'F1': 0}\n",
    "\n",
    "    _acc = accuracy_score(target_anomaly.reshape(-1), pred_anomaly.reshape(-1)) * 100\n",
    "    _precision = precision_score(target_anomaly.reshape(-1), pred_anomaly.reshape(-1)) * 100\n",
    "    _recall = recall_score(target_anomaly.reshape(-1), pred_anomaly.reshape(-1)) * 100\n",
    "    _f1 = f1_score(target_anomaly.reshape(-1), pred_anomaly.reshape(-1)) * 100\n",
    "\n",
    "\n",
    "    result['Acc'] = round(_acc, 2)\n",
    "    result['Precision'] = round(_precision, 2)\n",
    "    result['Recall'] = round(_recall, 2)\n",
    "    result['F1'] = round(_f1, 2)\n",
    "    \n",
    "    total_result[name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73edb00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss_1,2</th>\n",
       "      <td>97.62</td>\n",
       "      <td>32.84</td>\n",
       "      <td>65.96</td>\n",
       "      <td>43.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_2</th>\n",
       "      <td>99.11</td>\n",
       "      <td>87.72</td>\n",
       "      <td>42.55</td>\n",
       "      <td>57.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_1,3</th>\n",
       "      <td>97.61</td>\n",
       "      <td>32.32</td>\n",
       "      <td>63.40</td>\n",
       "      <td>42.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_3</th>\n",
       "      <td>98.82</td>\n",
       "      <td>86.54</td>\n",
       "      <td>19.15</td>\n",
       "      <td>31.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Acc  Precision  Recall     F1\n",
       "Loss_1,2  97.62      32.84   65.96  43.85\n",
       "Loss_2    99.11      87.72   42.55  57.31\n",
       "Loss_1,3  97.61      32.32   63.40  42.82\n",
       "Loss_3    98.82      86.54   19.15  31.36"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.DataFrame(total_result)\n",
    "total_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8265b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "port_total_result = {loss: {} for loss in loss_list}\n",
    "\n",
    "for exp_dir in dirs:\n",
    "    if exp_dir.split('/')[-2].split('_')[-3] == 'all':\n",
    "        if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "            name = 'Loss_1,2'\n",
    "        else:\n",
    "            name = \"Loss_2\"\n",
    "    else:\n",
    "        if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "            name = 'Loss_1,3'\n",
    "        else:\n",
    "            name = \"Loss_3\"\n",
    "            \n",
    "    config, _, test_result = get_exp_result_files(exp_dir)\n",
    "    \n",
    "    if exp_dir.split('/')[-2].split('_')[-2] == 'combine':\n",
    "        pred_anomaly = torch.sigmoid(torch.Tensor(test_result['anomaly_pred'])) > 0.5\n",
    "        \n",
    "    else:\n",
    "        node_by_node_pred = []\n",
    "        forecast = test_result['forecast'].squeeze()\n",
    "        \n",
    "        for node in range(5):\n",
    "            port_forecast = forecast[:,node,:]\n",
    "\n",
    "            inv_port_forecast = inv_std_scaler(port_forecast.reshape(-1), mean[node], std[node])\n",
    "            inv_port_forecast = inv_port_forecast.reshape(forecast.shape[0], -1)\n",
    "\n",
    "            inv_port_forecast = inv_port_forecast[:, -1]\n",
    "\n",
    "            pred_anomaly = inv_port_forecast < 1000\n",
    "\n",
    "            node_by_node_pred.append(torch.Tensor(pred_anomaly))\n",
    "\n",
    "        pred_anomaly = torch.stack(node_by_node_pred, axis=0).T\n",
    "    \n",
    "    \n",
    "    port_result = {port: {} for port in port_list}    \n",
    "    \n",
    "    for idx, port in enumerate(port_list):\n",
    "        _result = {'Acc': 0, 'Precision': 0, 'Recall': 0, 'F1': 0}\n",
    "\n",
    "        _acc = accuracy_score(target_anomaly[:, idx], pred_anomaly[:, idx]) * 100\n",
    "        _precision = precision_score(target_anomaly[:, idx], pred_anomaly[:, idx]) * 100\n",
    "        _recall = recall_score(target_anomaly[:, idx], pred_anomaly[:, idx]) * 100\n",
    "        _f1 = f1_score(target_anomaly[:, idx], pred_anomaly[:, idx]) * 100\n",
    "\n",
    "\n",
    "        _result['Acc'] = round(_acc, 2)\n",
    "        _result['Precision'] = round(_precision, 2)\n",
    "        _result['Recall'] = round(_recall, 2)\n",
    "        _result['F1'] = round(_f1, 2)\n",
    "\n",
    "        port_result[port] = _result\n",
    "        \n",
    "    port_total_result[name] = port_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "70140dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = []\n",
    "for loss in loss_list:\n",
    "    loss_df.append(pd.DataFrame(port_total_result[loss]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2e5a435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>증산도</th>\n",
       "      <td>99.19</td>\n",
       "      <td>93.75</td>\n",
       "      <td>36.59</td>\n",
       "      <td>52.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불무기도</th>\n",
       "      <td>98.68</td>\n",
       "      <td>86.67</td>\n",
       "      <td>50.65</td>\n",
       "      <td>63.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>장도</th>\n",
       "      <td>98.26</td>\n",
       "      <td>88.00</td>\n",
       "      <td>45.83</td>\n",
       "      <td>60.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>목포</th>\n",
       "      <td>99.43</td>\n",
       "      <td>66.67</td>\n",
       "      <td>10.00</td>\n",
       "      <td>17.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>여수항</th>\n",
       "      <td>99.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acc  Precision  Recall     F1\n",
       "증산도   99.19      93.75   36.59  52.63\n",
       "불무기도  98.68      86.67   50.65  63.93\n",
       "장도    98.26      88.00   45.83  60.27\n",
       "목포    99.43      66.67   10.00  17.39\n",
       "여수항   99.97       0.00    0.00   0.00"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
